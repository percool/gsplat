{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function: Render multi-view images by poses from a pretrained GS model (gsplat) and save them to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "from dataclasses import dataclass, field\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import imageio\n",
    "import nerfview\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "import tyro\n",
    "import viser\n",
    "import yaml\n",
    "from datasets.colmap import Dataset, Parser\n",
    "from datasets.traj import (\n",
    "    generate_interpolated_path,\n",
    "    generate_ellipse_path_z,\n",
    "    generate_spiral_path,\n",
    ")\n",
    "from torch import Tensor\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchmetrics.image import PeakSignalNoiseRatio, StructuralSimilarityIndexMeasure\n",
    "from fused_ssim import fused_ssim\n",
    "from torchmetrics.image.lpip import LearnedPerceptualImagePatchSimilarity\n",
    "from typing_extensions import Literal, assert_never\n",
    "from utils import AppearanceOptModule, CameraOptModule, knn, rgb_to_sh, set_random_seed\n",
    "from lib_bilagrid import (\n",
    "    BilateralGrid,\n",
    "    slice,\n",
    "    color_correct,\n",
    "    total_variation_loss,\n",
    ")\n",
    "\n",
    "from gsplat.compression import PngCompression\n",
    "from gsplat.distributed import cli\n",
    "from gsplat.rendering import rasterization\n",
    "from gsplat.strategy import DefaultStrategy, MCMCStrategy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: image_path not found for reconstruction\n",
      "[Parser] 202 images, taken by 1 cameras.\n"
     ]
    }
   ],
   "source": [
    "from simple_trainer import Runner,Config\n",
    "# current path is ./examples\n",
    "cfg1=Config(data_dir=\"/home/percool/CLab/ggs/datasets/co3d/apple/189_20393_38136_part/\",\\\n",
    "            result_dir=\"results/apple_189_part_1_unnorm\",\\\n",
    "                )\n",
    "cfg2=Config(data_dir=\"/home/percool/CLab/ggs/datasets/co3d/apple/189_20393_38136/\")\n",
    "# Load data: Training data should contain initial points and colors.\n",
    "# parser1 = Parser(\n",
    "#     data_dir=cfg1.data_dir,\n",
    "#     factor=cfg1.data_factor,\n",
    "#     normalize=cfg1.normalize_world_space,\n",
    "#     test_every=cfg1.test_every,\n",
    "# )\n",
    "parser2 = Parser(\n",
    "    data_dir=cfg2.data_dir,\n",
    "    factor=cfg2.data_factor,\n",
    "    normalize=cfg2.normalize_world_space,\n",
    "    test_every=cfg2.test_every,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg1.data_factor\n",
    "# parser2.imsize_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runner2(Runner):\n",
    "    def __init__(\n",
    "        self, cfg: Config\n",
    "    ) -> None:\n",
    "        super().__init__(0,0,1,cfg)\n",
    "    \n",
    "    def load_Gaussian_splats(self, ckpt_path: str) -> None:\n",
    "        \"\"\"Load splats from a file.\"\"\"\n",
    "        print(\"Loading splats from %s...\" % ckpt_path)\n",
    "        device=self.device\n",
    "        means, quats, scales, opacities, sh0, shN = [], [], [], [], [], []\n",
    "        if ckpt_path.endswith(\".pt\"):\n",
    "            ckpt = torch.load(ckpt_path, map_location=device)[\"splats\"]\n",
    "            means.append(ckpt[\"means\"])\n",
    "            quats.append(F.normalize(ckpt[\"quats\"], p=2, dim=-1))\n",
    "            scales.append(torch.exp(ckpt[\"scales\"]))\n",
    "            opacities.append(torch.sigmoid(ckpt[\"opacities\"]))\n",
    "            sh0.append(ckpt[\"sh0\"])\n",
    "            shN.append(ckpt[\"shN\"])\n",
    "        self.means = torch.cat(means, dim=0)\n",
    "        self.quats = torch.cat(quats, dim=0)\n",
    "        self.scales = torch.cat(scales, dim=0)\n",
    "        self.opacities = torch.cat(opacities, dim=0)\n",
    "        self.sh0 = torch.cat(sh0, dim=0)\n",
    "        self.shN = torch.cat(shN, dim=0)\n",
    "        self.colors = torch.cat([self.sh0, self.shN], dim=-2)\n",
    "        self.sh_degree = int(math.sqrt(self.colors.shape[-2]) - 1)\n",
    "\n",
    "    # @torch.no_grad()\n",
    "    # def viewer_render_fn(self,camera_state: nerfview.CameraState, img_wh: Tuple[int, int]):\n",
    "    #     device=self.device\n",
    "    #     width, height = img_wh\n",
    "    #     c2w = camera_state.c2w\n",
    "    #     K = camera_state.get_K(img_wh)\n",
    "    #     c2w = torch.from_numpy(c2w).float().to(device)\n",
    "    #     K = torch.from_numpy(K).float().to(device)\n",
    "    #     viewmat = c2w.inverse()\n",
    "\n",
    "    #     backend=\"gsplat\"\n",
    "    #     if backend == \"gsplat\":\n",
    "    #         rasterization_fn = rasterization\n",
    "    #     elif backend == \"inria\":\n",
    "    #         from gsplat import rasterization_inria_wrapper\n",
    "\n",
    "    #         rasterization_fn = rasterization_inria_wrapper\n",
    "    #     else:\n",
    "    #         raise ValueError\n",
    "\n",
    "    #     render_colors, render_alphas, meta = rasterization_fn(\n",
    "    #         self.means,  # [N, 3]\n",
    "    #         self.quats,  # [N, 4]\n",
    "    #         self.scales,  # [N, 3]\n",
    "    #         self.opacities,  # [N]\n",
    "    #         self.colors,  # [N, 3]\n",
    "    #         viewmat[None],  # [1, 4, 4]\n",
    "    #         K[None],  # [1, 3, 3]\n",
    "    #         width,\n",
    "    #         height,\n",
    "    #         sh_degree=self.sh_degree,\n",
    "    #         render_mode=\"RGB+ED\",\n",
    "    #         # this is to speedup large-scale rendering by skipping far-away Gaussians.\n",
    "    #         # radius_clip=3,\n",
    "    #     )\n",
    "    #     render_rgbs = render_colors[0, ..., 0:3].cpu().numpy()\n",
    "    #     return render_rgbs\n",
    "    \n",
    "    \n",
    "    def rasterize_splats2(\n",
    "        self,\n",
    "        camtoworlds: Tensor,\n",
    "        Ks: Tensor,\n",
    "        width: int,\n",
    "        height: int,\n",
    "        **kwargs,\n",
    "    ) -> Tuple[Tensor, Tensor, Dict]:\n",
    "        means = self.means  # [N, 3]\n",
    "        # quats = F.normalize(self.splats[\"quats\"], dim=-1)  # [N, 4]\n",
    "        # rasterization does normalization internally\n",
    "        quats = self.quats  # [N, 4]\n",
    "        scales = self.scales  # [N, 3]\n",
    "        opacities = self.opacities  # [N,]\n",
    "\n",
    "        image_ids = kwargs.pop(\"image_ids\", None)\n",
    "        if self.cfg.app_opt:\n",
    "            colors = self.app_module(\n",
    "                features=self.splats[\"features\"],\n",
    "                embed_ids=image_ids,\n",
    "                dirs=means[None, :, :] - camtoworlds[:, None, :3, 3],\n",
    "                sh_degree=kwargs.pop(\"sh_degree\", self.cfg.sh_degree),\n",
    "            )\n",
    "            colors = colors + self.splats[\"colors\"]\n",
    "            colors = torch.sigmoid(colors)\n",
    "        else:\n",
    "            # colors = torch.cat([self.splats[\"sh0\"], self.splats[\"shN\"]], 1)  # [N, K, 3]\n",
    "            colors=self.colors\n",
    "\n",
    "        rasterize_mode = \"antialiased\" if self.cfg.antialiased else \"classic\"\n",
    "        render_colors, render_alphas, info = rasterization(\n",
    "            means=means,\n",
    "            quats=quats,\n",
    "            scales=scales,\n",
    "            opacities=opacities,\n",
    "            colors=colors,\n",
    "            viewmats=torch.linalg.inv(camtoworlds),  # [C, 4, 4]\n",
    "            Ks=Ks,  # [C, 3, 3]\n",
    "            width=width,\n",
    "            height=height,\n",
    "            packed=self.cfg.packed,\n",
    "            absgrad=(\n",
    "                self.cfg.strategy.absgrad\n",
    "                if isinstance(self.cfg.strategy, DefaultStrategy)\n",
    "                else False\n",
    "            ),\n",
    "            sparse_grad=self.cfg.sparse_grad,\n",
    "            rasterize_mode=rasterize_mode,\n",
    "            distributed=self.world_size > 1,\n",
    "            **kwargs,\n",
    "        )\n",
    "        return render_colors, render_alphas, info\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def render_by_poses(self, parser_new: Parser)->None:\n",
    "        \"\"\"Entry for rendering by poses.\"\"\"\n",
    "        print(\"Running poses-based rendering...\")\n",
    "        cfg = self.cfg\n",
    "        device = self.device\n",
    "\n",
    "        camtoworlds_all = parser_new.camtoworlds\n",
    "\n",
    "        # camtoworlds_all = np.concatenate(\n",
    "        #     [\n",
    "        #         camtoworlds_all,\n",
    "        #         np.repeat(\n",
    "        #             np.array([[[0.0, 0.0, 0.0, 1.0]]]), len(camtoworlds_all), axis=0\n",
    "        #         ),\n",
    "        #     ],\n",
    "        #     axis=1,\n",
    "        # )  # [N, 4, 4]\n",
    "\n",
    "        camtoworlds_all = torch.from_numpy(camtoworlds_all).float().to(device)\n",
    "        K = torch.from_numpy(list(self.parser.Ks_dict.values())[0]).float().to(device)\n",
    "        width, height = list(self.parser.imsize_dict.values())[0]\n",
    "\n",
    "        canvas_all,canvas_rgb_all,canvas_depth_all = [],[],[]\n",
    "        for i in tqdm.trange(len(camtoworlds_all), desc=\"Rendering trajectory\"):\n",
    "            camtoworlds = camtoworlds_all[i : i + 1]\n",
    "            Ks = K[None]\n",
    "\n",
    "            renders, _, _ = self.rasterize_splats2(\n",
    "                camtoworlds=camtoworlds,\n",
    "                Ks=Ks,\n",
    "                width=width,\n",
    "                height=height,\n",
    "                sh_degree=cfg.sh_degree,\n",
    "                near_plane=cfg.near_plane,\n",
    "                far_plane=cfg.far_plane,\n",
    "                render_mode=\"RGB+ED\",\n",
    "            )  # [1, H, W, 4]\n",
    "            colors = torch.clamp(renders[..., 0:3], 0.0, 1.0)  # [1, H, W, 3]\n",
    "            depths = renders[..., 3:4]  # [1, H, W, 1]\n",
    "            depths = (depths - depths.min()) / (depths.max() - depths.min())\n",
    "            canvas_list = [colors, depths.repeat(1, 1, 1, 3)]\n",
    "\n",
    "            # write images\n",
    "            canvas = torch.cat(canvas_list, dim=2).squeeze(0).cpu().numpy()\n",
    "            canvas = (canvas * 255).astype(np.uint8)\n",
    "            canvas_all.append(canvas)\n",
    "\n",
    "            canvas_rgb = colors.squeeze(0).cpu().numpy()\n",
    "            canvas_rgb = (canvas_rgb * 255).astype(np.uint8)\n",
    "            canvas_rgb_all.append(canvas_rgb)\n",
    "\n",
    "            canvas_depth = depths.repeat(1, 1, 1, 3).squeeze(0).cpu().numpy()\n",
    "            canvas_depth = (canvas_depth * 255).astype(np.uint8)\n",
    "            canvas_depth_all.append(canvas_depth)\n",
    "\n",
    "        # save to images\n",
    "        images_dir = f\"{cfg.result_dir}/images_poses\"\n",
    "        folders = [images_dir+\"/rgb\",images_dir+\"/depth\",images_dir+\"/combined\"]\n",
    "        canvases=[canvas_rgb_all,canvas_depth_all,canvas_all]\n",
    "        for folder_onetype,canvas_onetype in zip(folders,canvases):\n",
    "            os.makedirs(folder_onetype, exist_ok=True)\n",
    "            for canvas,name in zip(canvas_onetype,parser_new.image_names):\n",
    "                imageio.imwrite(f\"{folder_onetype}/{name}\", canvas)\n",
    "        print(f\"Images saved to {images_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: image_path not found for reconstruction\n",
      "[Parser] 30 images, taken by 1 cameras.\n",
      "Scene scale: 1.63017629678518\n",
      "Model initialized. Number of GS: 10071\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────── <span style=\"font-weight: bold\">viser</span> ───────────────╮\n",
       "│             ╷                       │\n",
       "│   HTTP      │ http://0.0.0.0:8080   │\n",
       "│   Websocket │ ws://0.0.0.0:8080     │\n",
       "│             ╵                       │\n",
       "╰─────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────── \u001b[1mviser\u001b[0m ───────────────╮\n",
       "│             ╷                       │\n",
       "│   HTTP      │ http://0.0.0.0:8080   │\n",
       "│   Websocket │ ws://0.0.0.0:8080     │\n",
       "│             ╵                       │\n",
       "╰─────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading splats from results/apple_189_part_1_unnorm/ckpts/ckpt_29999_rank0.pt...\n",
      "Running poses-based rendering...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rendering trajectory: 100%|██████████| 202/202 [00:02<00:00, 81.84it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images saved to results/apple_189_part_1_unnorm/images_poses\n"
     ]
    }
   ],
   "source": [
    "runner2=Runner2(cfg1)\n",
    "runner2.load_Gaussian_splats(\"results/apple_189_part_1_unnorm/ckpts/ckpt_29999_rank0.pt\")\n",
    "runner2.render_by_poses(parser2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsplat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
